<!-- комментарий-->
<!--ссылка на файл <a href='https://github.com/PavlyukovVladimir/SMPR/blob/master/scripts/NNBayes.R'>NNBayes.R</a>-->
<!--вставка картинки <img src="img/omega.jpg" alt="вероятность_собятия">-->

<base href="https://github.com/PavlyukovVladimir/SMPR2/blob/master/" ></base>
<a name="navigation"></a><!--Якорь для Навигации-->

## Навигация

<p><a href="#ak"><h1>1. Алгоритмы классификации</h1></a></p>
<p><a href="#mak"><h2>1.1. Метрические алгоритмы классификации</h2></a></p>
<p><a href="#bak"><h2>1.2. Байесовские алгоритмы классификации</h2></a></p>
<p><a href="#bak"><h2>1.3. Линейные алгоритмы классификации</h2></a></p>
<p><a href="#mvr"><h1>2. Методы восстановления регрессии</h1></a></p>
<p><a href="#fnw"><h1>2.1. Непараметрическая регрессия. Формула Надарая – Ватсона</h1></a></p>


 
<h1 align="center">1. Алгоритмы классификации</h1><a name="ak"></a>

<h2>1.1. Метрические алгоритмы классификации</h2><a name="mak"></a>
<li>Используя готовые методы из библиотеки sklearn, применить алгоритмы классификации, основанные на методе ближайших соседей и методе парзеновского окна (использовать различные ядра) для классификации исходных данных.</li>
<li>Оптимальные параметры выбирать по критерию скользящего контроля.</li>
<li>Оценить качество построенных алгоритмов.</li>
<p></p>
<p>Решение оформлено в Jupyter notebook, страница с решением: <a href='Jupyter-notebook-notes/Metricheskiye_algoritmy_klassifikatcii.ipynb'>Metricheskiye_algoritmy_klassifikatcii.ipynb</a></p>
<p><a href="#navigation"><b>Вверх к навигации</b></a></p>

<h2>1.2. Байесовские алгоритмы классификации</h2><a name="bak"></a>
<li>Используя готовые методы из библиотеки sklearn, применить байесовские алгоритмы классификации «наивный байес», линейный дискриминант Фишера и plug-in алгоритм для классификации исходных данных.</li>
<li>Оценить качество построенных алгоритмов.</li>
<p></p>
<p>Решение оформлено в Jupyter notebook, страница с решением: <strong><font color="green">не решено</font></strong></p>
<p><a href="#navigation"><b>Вверх к навигации</b></a></p>

<h2>1.3. Линейные алгоритмы классификации</h2><a name="lak"></a>
<li>Используя готовые методы из библиотеки sklearn, применить линейные алгоритмы для классификации исходных данных.</li>
<li>Оценить качество построенных алгоритмов.</li>
<p></p>
<p>Решение оформлено в Jupyter notebook, страница с решением: <b >не решено</b></p>
<p><a href="#navigation"><b>Вверх к навигации</b></a></p>

<h1 align="center">2. Методы восстановления регрессии</h1><a name="mvr"></a>

<h2>2.1. Непараметрическая регрессия. Формула Надарая – Ватсона</h2><a name="fnw"></a>
<li>Реализовать метод ядерного сглаживания Надарая – Ватсона с гауссовским и квартическим ядрами.</li>
<li>Предоставить возможность настраивать все параметры алгоритма.</li>
<li>Сравнить SSE для гауссовского и квартического ядер.</li>
<li>Сделать выводы.</li>
<p></p>
<p>Решение оформлено в Jupyter notebook, страница с решением: <b>не решено</b></p>
<p><a href="#navigation"><b>Вверх к навигации</b></a></p>
